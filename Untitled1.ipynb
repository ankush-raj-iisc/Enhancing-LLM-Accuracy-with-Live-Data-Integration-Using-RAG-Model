{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c4e4326-8bff-48af-80d8-6b248b589e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: serpapi in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.1.5)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (from serpapi) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->serpapi) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->serpapi) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->serpapi) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->serpapi) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install serpapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9e6dae9-a414-4b0a-befd-dc43002825b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import serpapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6bcc544-522e-4f8b-9f90-2ebc0a7bb7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi.serp_api_client import *\n",
    "\n",
    "class GoogleSearch(SerpApiClient):\n",
    "    \"\"\"GoogleSearch enables to search google and parse the result.\n",
    "    ```python\n",
    "    from serpapi import GoogleSearch\n",
    "    query = GoogleSearch({\"q\": \"coffee\", \"location\": \"Austin,Texas\"})\n",
    "    data = query.get_json()\n",
    "    ```\n",
    "\n",
    "    https://github.com/serpapi/google-search-results-python\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params_dict):\n",
    "        super(GoogleSearch, self).__init__(params_dict, GOOGLE_ENGINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9779d270-f8f2-4e90-92b4-0f6580eb7903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results saved to serpapi_results.csv\n"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "import csv\n",
    "\n",
    "# Your serpapi parameters\n",
    "params = {\n",
    "    \"engine\": \"duckduckgo\",\n",
    "    \"q\": \"Canoo, a publicly traded company listed on NASDAQ (ticker symbol: GOEV)\",\n",
    "    \"kl\": \"in-en\",\n",
    "    \"api_key\": \"API-KEY\"  # Use your actual API key\n",
    "}\n",
    "\n",
    "search = GoogleSearch(params)\n",
    "results = search.get_dict()\n",
    "\n",
    "# Define the filename where you want to store the results\n",
    "filename = 'serpapi_results.csv'\n",
    "\n",
    "# Define the CSV headers\n",
    "headers = ['Title', 'Link']\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(headers)  # Write the header row\n",
    "    \n",
    "    # Check if the 'organic_results' key is in the results\n",
    "    if 'organic_results' in results:\n",
    "        for result in results['organic_results']:\n",
    "            # Each 'result' is a dictionary. We're interested in the 'title' and 'link' keys.\n",
    "            title = result.get('title', 'No Title Found')\n",
    "            link = result.get('link', 'No Link Found')\n",
    "            writer.writerow([title, link])  # Write the result row to the CSV\n",
    "\n",
    "print(f\"Search results saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b1a3a5-92ad-4cb9-958a-662a28993ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "589930e0-3246-474f-a697-6cb72fba2621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be31417f-ab2a-4444-8bdb-f1e5f7d84a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas requests beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b90f305-da39-4d4b-9a39-416494405857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping https://ih.advfn.com/stock-market/NASDAQ/canoo-GOEV/stock-price: Message: disconnected: not connected to DevTools\n",
      "  (failed to check if window was closed: disconnected: not connected to DevTools)\n",
      "  (Session info: chrome=121.0.6167.185)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00E4E123+48179]\n",
      "\t(No symbol) [0x00DD5D01]\n",
      "\t(No symbol) [0x00CBD72D]\n",
      "\t(No symbol) [0x00CAE3CE]\n",
      "\t(No symbol) [0x00CC65BA]\n",
      "\t(No symbol) [0x00D2AD19]\n",
      "\t(No symbol) [0x00D13A26]\n",
      "\t(No symbol) [0x00CEB7BC]\n",
      "\t(No symbol) [0x00CEC62D]\n",
      "\tGetHandleVerifier [0x01167C33+3299139]\n",
      "\tGetHandleVerifier [0x011A5BF2+3553026]\n",
      "\tGetHandleVerifier [0x011A0BCC+3532508]\n",
      "\tGetHandleVerifier [0x00EE494E+664670]\n",
      "\t(No symbol) [0x00DE0AB4]\n",
      "\t(No symbol) [0x00DDBF08]\n",
      "\t(No symbol) [0x00DDC02D]\n",
      "\t(No symbol) [0x00DCDD00]\n",
      "\tBaseThreadInitThunk [0x76817BA9+25]\n",
      "\tRtlInitializeExceptionChain [0x7778BD2B+107]\n",
      "\tRtlClearBits [0x7778BCAF+191]\n",
      "\n",
      "Error scraping https://symbolismdesk.com/canoo-electric-car-stock-symbol/: Message: disconnected: not connected to DevTools\n",
      "  (failed to check if window was closed: disconnected: not connected to DevTools)\n",
      "  (Session info: chrome=121.0.6167.185)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00E4E123+48179]\n",
      "\t(No symbol) [0x00DD5D01]\n",
      "\t(No symbol) [0x00CBD72D]\n",
      "\t(No symbol) [0x00CAE3CE]\n",
      "\t(No symbol) [0x00CADFC9]\n",
      "\t(No symbol) [0x00CBF360]\n",
      "\t(No symbol) [0x00D2A2F6]\n",
      "\t(No symbol) [0x00D13A26]\n",
      "\t(No symbol) [0x00CEB7BC]\n",
      "\t(No symbol) [0x00CEC62D]\n",
      "\tGetHandleVerifier [0x01167C33+3299139]\n",
      "\tGetHandleVerifier [0x011A5BF2+3553026]\n",
      "\tGetHandleVerifier [0x011A0BCC+3532508]\n",
      "\tGetHandleVerifier [0x00EE494E+664670]\n",
      "\t(No symbol) [0x00DE0AB4]\n",
      "\t(No symbol) [0x00DDBF08]\n",
      "\t(No symbol) [0x00DDC02D]\n",
      "\t(No symbol) [0x00DCDD00]\n",
      "\tBaseThreadInitThunk [0x76817BA9+25]\n",
      "\tRtlInitializeExceptionChain [0x7778BD2B+107]\n",
      "\tRtlClearBits [0x7778BCAF+191]\n",
      "\n",
      "Error scraping https://www.nasdaq.com/market-activity/stocks/goev/insider-activity: Message: disconnected: not connected to DevTools\n",
      "  (failed to check if window was closed: disconnected: not connected to DevTools)\n",
      "  (Session info: chrome=121.0.6167.185)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00E4E123+48179]\n",
      "\t(No symbol) [0x00DD5D01]\n",
      "\t(No symbol) [0x00CBD72D]\n",
      "\t(No symbol) [0x00CAE3CE]\n",
      "\t(No symbol) [0x00CADFC9]\n",
      "\t(No symbol) [0x00CBF360]\n",
      "\t(No symbol) [0x00D2A2F6]\n",
      "\t(No symbol) [0x00D13A26]\n",
      "\t(No symbol) [0x00CEB7BC]\n",
      "\t(No symbol) [0x00CEC62D]\n",
      "\tGetHandleVerifier [0x01167C33+3299139]\n",
      "\tGetHandleVerifier [0x011A5BF2+3553026]\n",
      "\tGetHandleVerifier [0x011A0BCC+3532508]\n",
      "\tGetHandleVerifier [0x00EE494E+664670]\n",
      "\t(No symbol) [0x00DE0AB4]\n",
      "\t(No symbol) [0x00DDBF08]\n",
      "\t(No symbol) [0x00DDC02D]\n",
      "\t(No symbol) [0x00DCDD00]\n",
      "\tBaseThreadInitThunk [0x76817BA9+25]\n",
      "\tRtlInitializeExceptionChain [0x7778BD2B+107]\n",
      "\tRtlClearBits [0x7778BCAF+191]\n",
      "\n",
      "Error scraping https://investorplace.com/2023/03/7-ev-stocks-to-sell-as-competition-heats-up/: Message: disconnected: not connected to DevTools\n",
      "  (failed to check if window was closed: disconnected: not connected to DevTools)\n",
      "  (Session info: chrome=121.0.6167.185)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00E4E123+48179]\n",
      "\t(No symbol) [0x00DD5D01]\n",
      "\t(No symbol) [0x00CBD72D]\n",
      "\t(No symbol) [0x00CAE3CE]\n",
      "\t(No symbol) [0x00CADFC9]\n",
      "\t(No symbol) [0x00CBF360]\n",
      "\t(No symbol) [0x00D2A2F6]\n",
      "\t(No symbol) [0x00D13A26]\n",
      "\t(No symbol) [0x00CEB7BC]\n",
      "\t(No symbol) [0x00CEC62D]\n",
      "\tGetHandleVerifier [0x01167C33+3299139]\n",
      "\tGetHandleVerifier [0x011A5BF2+3553026]\n",
      "\tGetHandleVerifier [0x011A0BCC+3532508]\n",
      "\tGetHandleVerifier [0x00EE494E+664670]\n",
      "\t(No symbol) [0x00DE0AB4]\n",
      "\t(No symbol) [0x00DDBF08]\n",
      "\t(No symbol) [0x00DDC02D]\n",
      "\t(No symbol) [0x00DCDD00]\n",
      "\tBaseThreadInitThunk [0x76817BA9+25]\n",
      "\tRtlInitializeExceptionChain [0x7778BD2B+107]\n",
      "\tRtlClearBits [0x7778BCAF+191]\n",
      "\n",
      "Error scraping https://www.washingtonpost.com/technology/2024/02/15/truth-social-trump-merger-sec/: Message: disconnected: not connected to DevTools\n",
      "  (failed to check if window was closed: disconnected: not connected to DevTools)\n",
      "  (Session info: chrome=121.0.6167.185)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00E4E123+48179]\n",
      "\t(No symbol) [0x00DD5D01]\n",
      "\t(No symbol) [0x00CBD72D]\n",
      "\t(No symbol) [0x00CAE3CE]\n",
      "\t(No symbol) [0x00CADFC9]\n",
      "\t(No symbol) [0x00CBF360]\n",
      "\t(No symbol) [0x00D2A2F6]\n",
      "\t(No symbol) [0x00D13A26]\n",
      "\t(No symbol) [0x00CEB7BC]\n",
      "\t(No symbol) [0x00CEC62D]\n",
      "\tGetHandleVerifier [0x01167C33+3299139]\n",
      "\tGetHandleVerifier [0x011A5BF2+3553026]\n",
      "\tGetHandleVerifier [0x011A0BCC+3532508]\n",
      "\tGetHandleVerifier [0x00EE494E+664670]\n",
      "\t(No symbol) [0x00DE0AB4]\n",
      "\t(No symbol) [0x00DDBF08]\n",
      "\t(No symbol) [0x00DDC02D]\n",
      "\t(No symbol) [0x00DCDD00]\n",
      "\tBaseThreadInitThunk [0x76817BA9+25]\n",
      "\tRtlInitializeExceptionChain [0x7778BD2B+107]\n",
      "\tRtlClearBits [0x7778BCAF+191]\n",
      "\n",
      "Error scraping https://www.nasdaq.com/articles/are-canoo-nasdaq:goev-bulls-irrational-options-data-says-maybe-not: Message: disconnected: not connected to DevTools\n",
      "  (failed to check if window was closed: disconnected: not connected to DevTools)\n",
      "  (Session info: chrome=121.0.6167.185)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00E4E123+48179]\n",
      "\t(No symbol) [0x00DD5D01]\n",
      "\t(No symbol) [0x00CBD72D]\n",
      "\t(No symbol) [0x00CAE3CE]\n",
      "\t(No symbol) [0x00CADFC9]\n",
      "\t(No symbol) [0x00CBF360]\n",
      "\t(No symbol) [0x00D2A2F6]\n",
      "\t(No symbol) [0x00D13A26]\n",
      "\t(No symbol) [0x00CEB7BC]\n",
      "\t(No symbol) [0x00CEC62D]\n",
      "\tGetHandleVerifier [0x01167C33+3299139]\n",
      "\tGetHandleVerifier [0x011A5BF2+3553026]\n",
      "\tGetHandleVerifier [0x011A0BCC+3532508]\n",
      "\tGetHandleVerifier [0x00EE494E+664670]\n",
      "\t(No symbol) [0x00DE0AB4]\n",
      "\t(No symbol) [0x00DDBF08]\n",
      "\t(No symbol) [0x00DDC02D]\n",
      "\t(No symbol) [0x00DCDD00]\n",
      "\tBaseThreadInitThunk [0x76817BA9+25]\n",
      "\tRtlInitializeExceptionChain [0x7778BD2B+107]\n",
      "\tRtlClearBits [0x7778BCAF+191]\n",
      "\n",
      "Scraping completed and data saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Set up Chrome WebDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# Replace 'your_file_path.xls' with the path to your downloaded Excel file\n",
    "file_path = 'serpapi_results.csv'\n",
    "\n",
    "# Read the Excel file to get the URLs\n",
    "df = pd.read_csv(file_path)\n",
    "urls = df['Link'].tolist()  # Replace 'URL Column Name' with the actual column name containing URLs\n",
    "\n",
    "# Define your CSV file where the scraped data will be stored\n",
    "csv_file_path = 'scraped_data.csv'\n",
    "\n",
    "# Open a CSV file to write the scraped data\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the CSV header\n",
    "    writer.writerow(['URL', 'Scraped Data'])  # Modify header names based on what you're scraping\n",
    "\n",
    "    for url in urls:\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            scraped_data = driver.title\n",
    "    \n",
    "            writer.writerow([url, scraped_data])\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping {url}: {e}\")\n",
    "            writer.writerow([url, 'Failed to scrape'])\n",
    "\n",
    "    driver.quit()\n",
    "      \n",
    "\n",
    "print(\"Scraping completed and data saved to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0694225-b2e4-49a3-be54-b39046416161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.17.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.7)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dell\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d50a1960-ba6e-41d3-8bd5-38250f77231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02c0508b-001b-49b6-bb3a-79f016d2dba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\dell\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\lib\\site-packages (from webdriver-manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d136c8a-e482-4b9e-9e56-ace257b31cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d926794-42fc-430c-942f-ea1a2abdfb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Set up Chrome WebDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aa73525-73be-49f4-9bfb-e04ea039572d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 63\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[38;5;66;03m# Store data in a structured format (example)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m             data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     56\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch Query\u001b[39m\u001b[38;5;124m\"\u001b[39m: query,\n\u001b[0;32m     57\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: title,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[38;5;66;03m# Add extracted data as fields here, e.g., \"Industry\": industry_match.group(1) if industry_match else None, \"Market Share\": market_share_match.group(1) if market_share_match else None, ...\u001b[39;00m\n\u001b[0;32m     61\u001b[0m             }\n\u001b[1;32m---> 63\u001b[0m             writer\u001b[38;5;241m.\u001b[39mwriterow(data\u001b[38;5;241m.\u001b[39mvalues())  \u001b[38;5;66;03m# Write data row to CSV\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch results saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Define your search queries\n",
    "queries = [\n",
    "    \"Canoo industry analysis\",\n",
    "    \"Canoo competitors market share\",\n",
    "    \"Trends in electric vehicle industry\",\n",
    "    \"Canoo financial performance analysis\"\n",
    "]\n",
    "\n",
    "# Your SerpApi parameters (remember to use your own API key)\n",
    "params = {\n",
    "    \"engine\": \"duckduckgo\",\n",
    "    \"kl\": \"in-en\",\n",
    "    \"api_key\": \"API-KEY\"\n",
    "}\n",
    "\n",
    "# Define the filename and headers\n",
    "filename = 'serpapi_results.csv'\n",
    "headers = [\n",
    "    \"Search Query\",\n",
    "    \"Title\",\n",
    "    \"Snippet\",\n",
    "    \"Link\",\n",
    "    # Add more specific data fields here, e.g., \"Industry\", \"Market Share\", ...\n",
    "]\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(headers)\n",
    "\n",
    "# Iterate through search queries\n",
    "for query in queries:\n",
    "    # Replace 'num' with desired number of pages (if applicable)\n",
    "    params['q'] = query\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "\n",
    "    # Check for search results\n",
    "    if 'organic_results' in results:\n",
    "        for result in results['organic_results']:\n",
    "            title = result.get('title', 'No Title Found')\n",
    "            snippet = result.get('snippet', '')\n",
    "            link = result.get('link', 'No Link Found')\n",
    "\n",
    "            # Example data extraction using regular expressions (modify for your needs)\n",
    "            industry_match = re.search(r'Canoo is in the (.*?) industry', snippet)\n",
    "            market_share_match = re.search(r'(.*?)% market share', snippet)\n",
    "\n",
    "            # Store data in a structured format (example)\n",
    "            data = {\n",
    "                \"Search Query\": query,\n",
    "                \"Title\": title,\n",
    "                \"Snippet\": snippet,\n",
    "                \"Link\": link,\n",
    "                # Add extracted data as fields here, e.g., \"Industry\": industry_match.group(1) if industry_match else None, \"Market Share\": market_share_match.group(1) if market_share_match else None, ...\n",
    "            }\n",
    "\n",
    "            writer.writerow(data.values())  # Write data row to CSV\n",
    "\n",
    "print(f\"Search results saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d94ac89c-ab22-47dc-905d-b9a07ea76061",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 70\u001b[0m\n\u001b[0;32m     60\u001b[0m             data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     61\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch Query\u001b[39m\u001b[38;5;124m\"\u001b[39m: query,\n\u001b[0;32m     62\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: title,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMarket Share\u001b[39m\u001b[38;5;124m\"\u001b[39m: market_share_match,\n\u001b[0;32m     67\u001b[0m             }\n\u001b[0;32m     69\u001b[0m             \u001b[38;5;66;03m# Write data row to CSV\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m             writer\u001b[38;5;241m.\u001b[39mwriterow(data\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch results saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Define your search queries\n",
    "queries = [\n",
    "    \"Canoo industry analysis\",\n",
    "    \"Canoo competitors market share\",\n",
    "    \"Trends in electric vehicle industry\",\n",
    "    \"Canoo financial performance analysis\"\n",
    "]\n",
    "\n",
    "# Your SerpApi parameters (remember to use your own API key)\n",
    "params = {\n",
    "    \"engine\": \"duckduckgo\",\n",
    "    \"kl\": \"in-en\",\n",
    "   \"api_key\": \"API-KEY\"\n",
    "}\n",
    "\n",
    "# Define the filename and headers\n",
    "filename = 'serpapi_results.csv'\n",
    "headers = [\n",
    "    \"Search Query\",\n",
    "    \"Title\",\n",
    "    \"Snippet\",\n",
    "    \"Link\",\n",
    "    \"Industry\",  # Add data fields here\n",
    "    \"Market Share\",  # Add data fields here\n",
    "    # Add more specific data fields if needed\n",
    "]\n",
    "\n",
    "# Open the CSV file for writing (append mode to avoid rewriting headers)\n",
    "with open(filename, mode='a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write headers if file doesn't exist\n",
    "    if file.tell() == 0:\n",
    "        writer.writerow(headers)\n",
    "\n",
    "# Iterate through search queries\n",
    "for query in queries:\n",
    "    # Replace 'num' with desired number of pages (if applicable)\n",
    "    params['q'] = query\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "\n",
    "    # Check for search results\n",
    "    if 'organic_results' in results:\n",
    "        for result in results['organic_results']:\n",
    "            title = result.get('title', 'No Title Found')\n",
    "            snippet = result.get('snippet', '')\n",
    "            link = result.get('link', 'No Link Found')\n",
    "\n",
    "            # Example data extraction using regular expressions (modify for your needs)\n",
    "            industry_match = re.search(r'Canoo is in the (.*?) industry', snippet)\n",
    "            market_share_match = re.search(r'(.*?)% market share', snippet)\n",
    "\n",
    "            # Store data in a structured format\n",
    "            data = {\n",
    "                \"Search Query\": query,\n",
    "                \"Title\": title,\n",
    "                \"Snippet\": snippet,\n",
    "                \"Link\": link,\n",
    "                \"Industry\": industry_match,\n",
    "                \"Market Share\": market_share_match,\n",
    "            }\n",
    "\n",
    "            # Write data row to CSV\n",
    "            writer.writerow(data.values())\n",
    "\n",
    "print(f\"Search results saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e06887a-69bf-49a2-a2d7-0ddcd4a410ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results saved to serpapi_results.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from serpapi import GoogleSearch\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Define your search queries\n",
    "queries = [\n",
    "    \"Canoo industry analysis\",\n",
    "    \"Canoo competitors market share\",\n",
    "    \"Trends in electric vehicle industry\",\n",
    "    \"Canoo financial performance analysis\"\n",
    "]\n",
    "\n",
    "# Your SerpApi parameters (remember to use your own API key)\n",
    "params = {\n",
    "    \"engine\": \"duckduckgo\",\n",
    "    \"kl\": \"in-en\",\n",
    "    \"api_key\": \"API-KEY\"  # Use your actual API key\n",
    "}\n",
    "\n",
    "# Define the filename and headers for the CSV file\n",
    "filename = 'serpapi_results.csv'\n",
    "headers = [\"Search Query\", \"Title\", \"Snippet\", \"Link\"]\n",
    "\n",
    "# Open the CSV file for writing and write the headers\n",
    "with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    # Iterate through search queries\n",
    "    for query in queries:\n",
    "        params['q'] = query  # Update the query in the parameters\n",
    "        search = GoogleSearch(params)  # Create a GoogleSearch object with the updated parameters\n",
    "        results = search.get_dict()  # Fetch the results\n",
    "        \n",
    "        # Check for search results\n",
    "        if 'organic_results' in results:\n",
    "            for result in results['organic_results']:\n",
    "                title = result.get('title', 'No Title Found')\n",
    "                snippet = result.get('snippet', '')\n",
    "                link = result.get('link', 'No Link Found')\n",
    "                \n",
    "                # Write the data row to the CSV file\n",
    "                writer.writerow([query, title, snippet, link])\n",
    "\n",
    "print(f\"Search results saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adb2257b-420d-4a60-a5ce-c8be5fe5b4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results saved to serpapi_results1.csv\n"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "import csv\n",
    "\n",
    "# Corrected the missing closing bracket in the queries list\n",
    "queries = [\n",
    "    \"Identify the industry in which Canoo operates, along with its size, growth rate, trends, and key players.\"\n",
    "]\n",
    "\n",
    "# Your SerpApi parameters (remember to use your own API key)\n",
    "params = {\n",
    "    \"engine\": \"duckduckgo\",\n",
    "    \"kl\": \"in-en\",\n",
    "    \"api_key\": \"API-KEY\"  # Use your actual API key\n",
    "}\n",
    "\n",
    "# Define the filename and headers for the CSV file\n",
    "filename = 'serpapi_results1.csv'\n",
    "headers = [\"Search Query\", \"Title\", \"Snippet\", \"Link\"]\n",
    "\n",
    "# Open the CSV file for writing and write the headers\n",
    "with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    # Iterate through search queries\n",
    "    for query in queries:\n",
    "        params['q'] = query  # Update the query in the parameters\n",
    "        search = GoogleSearch(params)  # Create a GoogleSearch object with the updated parameters\n",
    "        results = search.get_dict()  # Fetch the results\n",
    "        \n",
    "        # Check for search results\n",
    "        if 'organic_results' in results:\n",
    "            for result in results['organic_results']:\n",
    "                title = result.get('title', 'No Title Found')\n",
    "                snippet = result.get('snippet', '')\n",
    "                link = result.get('link', 'No Link Found')\n",
    "                \n",
    "                # Write the data row to the CSV file\n",
    "                writer.writerow([query, title, snippet, link])\n",
    "\n",
    "print(f\"Search results saved to {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f64787e-5114-4cd6-a0ee-bece1cbabdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c542563-7190-410f-8249-48720320aa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted and saved to detailed_info.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Example URL - replace this with the actual URL(s) you intend to scrape\n",
    "df = pd.read_csv(\"serpapi_results1.csv\")\n",
    "urls = df['Link'].tolist()  # Replace 'URL Column Name' with the actual column name containing URLs\n",
    "\n",
    "\n",
    "# CSV setup\n",
    "filename = 'detailed_info.csv'\n",
    "headers = [\"URL\", \"Industry\", \"Industry Size\", \"Growth Rate\", \"Trends\", \"Key Players\"]\n",
    "\n",
    "with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    for url in urls:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # You need to replace the selectors below with actual selectors that match the content structure of your target webpage.\n",
    "        industry = soup.select_one('#industry-selector').get_text(strip=True) if soup.select_one('#industry-selector') else 'Not found'\n",
    "        industry_size = soup.select_one('#industry-size-selector').get_text(strip=True) if soup.select_one('#industry-size-selector') else 'Not found'\n",
    "        growth_rate = soup.select_one('#growth-rate-selector').get_text(strip=True) if soup.select_one('#growth-rate-selector') else 'Not found'\n",
    "        trends = soup.select_one('#trends-selector').get_text(strip=True) if soup.select_one('#trends-selector') else 'Not found'\n",
    "        key_players = soup.select_one('#key-players-selector').get_text(strip=True) if soup.select_one('#key-players-selector') else 'Not found'\n",
    "        \n",
    "        writer.writerow([url, industry, industry_size, growth_rate, trends, key_players])\n",
    "\n",
    "print(f\"Data extracted and saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "956144fd-adce-4fe4-9dfb-6a8bd78696c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search Query</th>\n",
       "      <th>Title</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>GitHub - theSuriya/Canoo-INC-Analysis</td>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>https://github.com/theSuriya/Canoo-INC-Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>CANOO TECHNOLOGIES Revenue, Growth &amp; Competito...</td>\n",
       "      <td>Canoo Technologies's annual revenues are over ...</td>\n",
       "      <td>https://incfact.com/company/canoo-torrance-ca/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Canoo - Wikipedia</td>\n",
       "      <td>Canoo Inc. is an American automotive company b...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Canoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Canoo, the EV startup that scored a deal with ...</td>\n",
       "      <td>Bing Guan—Bloomberg/Getty Images Good morning,...</td>\n",
       "      <td>https://fortune.com/2022/08/29/canoo-ev-startu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Canoo Reports Fourth Quarter and Full Year 202...</td>\n",
       "      <td>DALLAS, March 29, 2021 /PRNewswire/ -- Canoo (...</td>\n",
       "      <td>https://investors.canoo.com/news-presentations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Canoo Sticks to 2023 Production Target | Indus...</td>\n",
       "      <td>Canoo Sticks to 2023 Production Target | Indus...</td>\n",
       "      <td>https://www.industryweek.com/leadership/compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Canoo Inc. (GOEV) Statistics &amp; Valuation Metri...</td>\n",
       "      <td>Income Statement. In the last 12 months, Canoo...</td>\n",
       "      <td>https://stockanalysis.com/stocks/goev/statistics/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Canoo production starts could slip, but CEO re...</td>\n",
       "      <td>The global chip shortage and higher material c...</td>\n",
       "      <td>https://www.reuters.com/business/autos-transpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Canoo Inc. Announces Second Quarter 2023 Results</td>\n",
       "      <td>JUSTIN, Texas, Aug. 14, 2023 /PRNewswire/ -- C...</td>\n",
       "      <td>https://investors.canoo.com/news-presentations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Where Is Canoo Headed Tech-Wise, and How Fast ...</td>\n",
       "      <td>Canoo claims its total 12-volt operating syste...</td>\n",
       "      <td>https://www.motortrend.com/news/canoo-technolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Canoo Adds Key Leadership To Accelerate Growth</td>\n",
       "      <td>Canoo is a Los Angeles-based company that has ...</td>\n",
       "      <td>https://investors.canoo.com/news-presentations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Canoo: Differentiation Potential In EV Space, ...</td>\n",
       "      <td>Canoo says that it has a multi-phased approach...</td>\n",
       "      <td>https://seekingalpha.com/article/4412112-canoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Company Canoo Inc. - MarketScreener.com</td>\n",
       "      <td>Canoo Inc. is a mobility technology company en...</td>\n",
       "      <td>https://www.marketscreener.com/quote/stock/CAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Canoo Selects Google Cloud Technologies to Max...</td>\n",
       "      <td>Sunnyvale, CA - (August 29, 2023) - Google Clo...</td>\n",
       "      <td>https://www.press.canoo.com/press-release/cano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Canoo Vs Workhorse: Which Automobile Stock Is ...</td>\n",
       "      <td>Canoo's cash position, per its most recent 10-...</td>\n",
       "      <td>https://seekingalpha.com/article/4482945-canoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>GitHub - Mr-Vicky-01/Canoo-Inc-analysis</td>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>https://github.com/Mr-Vicky-01/Canoo-Inc-analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Steps Involved In This Analysis - GitHub</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "      <td>https://github.com/Mr-Vicky-01/Canoo-Inc-analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>How to Conduct an Industry Analysis? Steps, Te...</td>\n",
       "      <td>Industry analysis is the process of examining ...</td>\n",
       "      <td>https://www.appinio.com/en/blog/market-researc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Canoo selects Google Cloud technologies to max...</td>\n",
       "      <td>JUSTIN, Texas and SUNNYVALE, Calif., Aug. 29, ...</td>\n",
       "      <td>https://investors.canoo.com/news-presentations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Internship Coding Assignment</td>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>https://www.lizmotors.com/internship-coding-as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>Industry Analysis | Porter's Five Forces | Com...</td>\n",
       "      <td>Industry analysis—also known as Porter's Five ...</td>\n",
       "      <td>https://learn.marsdd.com/article/industry-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>CH 5 Flashcards | Quizlet</td>\n",
       "      <td>1. Industry structure - industry size and grow...</td>\n",
       "      <td>https://quizlet.com/161410893/ch-5-flash-cards/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>GitHub - theSuriya/Canoo-Analysis</td>\n",
       "      <td>Identify the industry in which Canoo operates,...</td>\n",
       "      <td>https://github.com/theSuriya/Canoo-Analysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Search Query  \\\n",
       "0   Identify the industry in which Canoo operates,...   \n",
       "1   Identify the industry in which Canoo operates,...   \n",
       "2   Identify the industry in which Canoo operates,...   \n",
       "3   Identify the industry in which Canoo operates,...   \n",
       "4   Identify the industry in which Canoo operates,...   \n",
       "5   Identify the industry in which Canoo operates,...   \n",
       "6   Identify the industry in which Canoo operates,...   \n",
       "7   Identify the industry in which Canoo operates,...   \n",
       "8   Identify the industry in which Canoo operates,...   \n",
       "9   Identify the industry in which Canoo operates,...   \n",
       "10  Identify the industry in which Canoo operates,...   \n",
       "11  Identify the industry in which Canoo operates,...   \n",
       "12  Identify the industry in which Canoo operates,...   \n",
       "13  Identify the industry in which Canoo operates,...   \n",
       "14  Identify the industry in which Canoo operates,...   \n",
       "15  Identify the industry in which Canoo operates,...   \n",
       "16  Identify the industry in which Canoo operates,...   \n",
       "17  Identify the industry in which Canoo operates,...   \n",
       "18  Identify the industry in which Canoo operates,...   \n",
       "19  Identify the industry in which Canoo operates,...   \n",
       "20  Identify the industry in which Canoo operates,...   \n",
       "21  Identify the industry in which Canoo operates,...   \n",
       "22  Identify the industry in which Canoo operates,...   \n",
       "\n",
       "                                                Title  \\\n",
       "0               GitHub - theSuriya/Canoo-INC-Analysis   \n",
       "1   CANOO TECHNOLOGIES Revenue, Growth & Competito...   \n",
       "2                                   Canoo - Wikipedia   \n",
       "3   Canoo, the EV startup that scored a deal with ...   \n",
       "4   Canoo Reports Fourth Quarter and Full Year 202...   \n",
       "5   Canoo Sticks to 2023 Production Target | Indus...   \n",
       "6   Canoo Inc. (GOEV) Statistics & Valuation Metri...   \n",
       "7   Canoo production starts could slip, but CEO re...   \n",
       "8    Canoo Inc. Announces Second Quarter 2023 Results   \n",
       "9   Where Is Canoo Headed Tech-Wise, and How Fast ...   \n",
       "10     Canoo Adds Key Leadership To Accelerate Growth   \n",
       "11  Canoo: Differentiation Potential In EV Space, ...   \n",
       "12            Company Canoo Inc. - MarketScreener.com   \n",
       "13  Canoo Selects Google Cloud Technologies to Max...   \n",
       "14  Canoo Vs Workhorse: Which Automobile Stock Is ...   \n",
       "15            GitHub - Mr-Vicky-01/Canoo-Inc-analysis   \n",
       "16           Steps Involved In This Analysis - GitHub   \n",
       "17  How to Conduct an Industry Analysis? Steps, Te...   \n",
       "18  Canoo selects Google Cloud technologies to max...   \n",
       "19                       Internship Coding Assignment   \n",
       "20  Industry Analysis | Porter's Five Forces | Com...   \n",
       "21                          CH 5 Flashcards | Quizlet   \n",
       "22                  GitHub - theSuriya/Canoo-Analysis   \n",
       "\n",
       "                                              Snippet  \\\n",
       "0   Identify the industry in which Canoo operates,...   \n",
       "1   Canoo Technologies's annual revenues are over ...   \n",
       "2   Canoo Inc. is an American automotive company b...   \n",
       "3   Bing Guan—Bloomberg/Getty Images Good morning,...   \n",
       "4   DALLAS, March 29, 2021 /PRNewswire/ -- Canoo (...   \n",
       "5   Canoo Sticks to 2023 Production Target | Indus...   \n",
       "6   Income Statement. In the last 12 months, Canoo...   \n",
       "7   The global chip shortage and higher material c...   \n",
       "8   JUSTIN, Texas, Aug. 14, 2023 /PRNewswire/ -- C...   \n",
       "9   Canoo claims its total 12-volt operating syste...   \n",
       "10  Canoo is a Los Angeles-based company that has ...   \n",
       "11  Canoo says that it has a multi-phased approach...   \n",
       "12  Canoo Inc. is a mobility technology company en...   \n",
       "13  Sunnyvale, CA - (August 29, 2023) - Google Clo...   \n",
       "14  Canoo's cash position, per its most recent 10-...   \n",
       "15  Identify the industry in which Canoo operates,...   \n",
       "16  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...   \n",
       "17  Industry analysis is the process of examining ...   \n",
       "18  JUSTIN, Texas and SUNNYVALE, Calif., Aug. 29, ...   \n",
       "19  Identify the industry in which Canoo operates,...   \n",
       "20  Industry analysis—also known as Porter's Five ...   \n",
       "21  1. Industry structure - industry size and grow...   \n",
       "22  Identify the industry in which Canoo operates,...   \n",
       "\n",
       "                                                 Link  \n",
       "0     https://github.com/theSuriya/Canoo-INC-Analysis  \n",
       "1      https://incfact.com/company/canoo-torrance-ca/  \n",
       "2                 https://en.wikipedia.org/wiki/Canoo  \n",
       "3   https://fortune.com/2022/08/29/canoo-ev-startu...  \n",
       "4   https://investors.canoo.com/news-presentations...  \n",
       "5   https://www.industryweek.com/leadership/compan...  \n",
       "6   https://stockanalysis.com/stocks/goev/statistics/  \n",
       "7   https://www.reuters.com/business/autos-transpo...  \n",
       "8   https://investors.canoo.com/news-presentations...  \n",
       "9   https://www.motortrend.com/news/canoo-technolo...  \n",
       "10  https://investors.canoo.com/news-presentations...  \n",
       "11  https://seekingalpha.com/article/4412112-canoo...  \n",
       "12  https://www.marketscreener.com/quote/stock/CAN...  \n",
       "13  https://www.press.canoo.com/press-release/cano...  \n",
       "14  https://seekingalpha.com/article/4482945-canoo...  \n",
       "15  https://github.com/Mr-Vicky-01/Canoo-Inc-analysis  \n",
       "16  https://github.com/Mr-Vicky-01/Canoo-Inc-analy...  \n",
       "17  https://www.appinio.com/en/blog/market-researc...  \n",
       "18  https://investors.canoo.com/news-presentations...  \n",
       "19  https://www.lizmotors.com/internship-coding-as...  \n",
       "20  https://learn.marsdd.com/article/industry-anal...  \n",
       "21    https://quizlet.com/161410893/ch-5-flash-cards/  \n",
       "22        https://github.com/theSuriya/Canoo-Analysis  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5098c-dd1d-482a-acc8-beff1174bbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
